# -*- coding: utf-8 -*-
"""Communicate Data FInding.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1synJHFfdN8xHGMOuAXSS_dVwVuostqXx

## DataFestAfrica Hackathon 2024: Improving  Academic Outcome For Secondary Education

## Introduction

An important general concern all over the African continent has been the sub-par quality of elementary and secondary education which has been further highlighted by the recent push to Computer-Based tests for students in ultimate classes (especially SSS3). In fairness, there has been some action taken by CSOs, governments and other bodies to improve the quality of education, and by extension, studentsâ€™ performance.

Recent statistics from JAMB (a Nigerian pre-tertiary examination governing body) shows that 76% (approx. 4 out of 5) of students who participated in the 2024 UTME scored less than 200 (50%). This interesting insight emphasizes the need to find proactive solutions to this problem.
 ## Deliverables
Analytical Models: Present the predictive models (if any) and analysis performed on the data.

Final Solution: Build a solution (report, app, visual, web page etc) that highlights the key insights, shows trends and correlations, and provides actionable recommendations for stakeholders to improve the performance of candidates

## Preliminary Wrangling
"""

# Commented out IPython magic to ensure Python compatibility.
# Import all packages and set plots to be embedded inline
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import rcParams
import seaborn as sns
sns.set_style("darkgrid")
plt.rcParams["figure.figsize"] = (10,4)
plt.rcParams["figure.dpi"] = 144
pd.set_option('display.max_columns', 30)
# %matplotlib inline

"""#### Loading the Dataset"""

# Load in the dataset into a pandas dataframe
online_review = pd.read_excel('Datafest_Hackathon.xlsx')

online_review = online_review.iloc[:, 1:]
online_review.head()

"""#### Assessing the Dataset"""

# Overview of data shape and composition
print(online_review.shape)
print(online_review.dtypes)

# Descriptive statistics for numeric variables
online_review.describe()

online_review.info()

online_review['Family support'].value_counts()

# convert the cols above into ordered categorical types
ordinal_var_dict = {'Exam readiness': ['Not well prepared','Somewhat prepared','Very well prepared'],
                    'Exam preparation': ['Not stressful','Moderately stressful','Extremely stressful'],
                    'Exam confidence': ['Not confident','Somewhat confident','Very confident'],
                  'Family support': ['Not supportive', 'Somewhat supportive', 'Very supportive']}

for var in ordinal_var_dict:
    ordered_var = pd.api.types.CategoricalDtype(ordered = True,
                                                categories = ordinal_var_dict[var])
    online_review[var] = online_review[var].astype(ordered_var)

online_review.head(3)

# # Saved cleaned data
# online_review.to_csv('ONLINE EDUCATION SYSTEM REVIEW CLEAN.csv', index=False)

online_review.describe()

"""## Univariate Exploration

I'll start by looking at the distribution of the main variable of interest: Satifaction level in Online Education(O.E)
"""

# Plotting all four together ()
fig, ax = plt.subplots(nrows=4, figsize = [16,12])

sns.countplot(data=online_review, x='Exam readiness',  ax=ax[0]).set(title='Exam readiness for Online Education')
sns.countplot(data=online_review, x='Exam preparation', ax=ax[1]).set(title='Exam preparation for Online Education')
sns.countplot(data=online_review, x='Exam confidence', ax=ax[2]).set(title='Exam confidence for Online Education')
sns.countplot(data=online_review, x='Family support', ax=ax[3]).set(title='Family support for Online Education')

plt.tight_layout();

"""Online performance seems to be generally above average with highest performace at 60%"""

print(online_review['Age'].value_counts(normalize=True)*100)
sns.countplot(data=online_review, x='Age').set(title='Distribution of Age');

"""From this chart we can infer that the teenage population(gen Z) were more involved in online education as compared to the youg adult population

Those in the middle class were more involved in the online education system, and majority where from the Urban areas as one would expect, with high prticipation from laptop users
"""

# Plot of Gender distribution
gendercount = round(online_review['Gender'].value_counts(normalize=True)*100,2)
plt.pie(gendercount, labels=[f"{str(x)}%" for x in gendercount.values], startangle=90, counterclock = False, wedgeprops = {'width': 0.5});
plt.title('Gender Distribution', fontsize=14)
plt.legend(gendercount.index);

"""The chart shows us that the female gender were more involve in the online education compared to the male"""

from wordcloud import WordCloud, STOPWORDS
from collections import Counter
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
import string

# Ensure you have necessary nltk packages
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('stopwords')

# Function to preprocess text and generate word cloud
def generate_wordcloud(df, column_name, title="Word Cloud"):
    """
    Preprocesses the text from the specified column of the DataFrame and generates a word cloud.

    Parameters:
    df (pd.DataFrame): The input DataFrame.
    column_name (str): The column name from which the word cloud will be generated.
    title (str): The title of the word cloud plot (default: 'Word Cloud').

    Returns:
    None: Displays the word cloud.
    """

    # Function to preprocess text
    def preprocess_text(text):
        # Convert to lowercase
        text = text.lower()

        # Remove punctuation
        text = text.translate(str.maketrans('', '', string.punctuation))

        # Tokenize words
        tokens = word_tokenize(text)

        # Remove stopwords
        tokens = [word for word in tokens if word not in stopwords.words('english')]

        # Lemmatize tokens
        lemmatizer = WordNetLemmatizer()
        tokens = [lemmatizer.lemmatize(word) for word in tokens]

        return tokens

    # Apply preprocessing to the specified column
    df['processed_text'] = df[column_name].apply(lambda x: preprocess_text(str(x)))

    # Flatten the list of lists into a single list of words
    all_words = [word for text in df['processed_text'] for word in text]

    # Create a frequency dictionary
    word_freq = Counter(all_words)

    # Generate word cloud
    wordcloud = WordCloud(width=600, height=300,  background_color='white',  max_words=100,  contour_color='black',  colormap='viridis',  stopwords=STOPWORDS).generate_from_frequencies(word_freq)

    # Display the word cloud
    plt.figure(figsize=(10, 4))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis('off')
    plt.title(title)
    plt.show()

generate_wordcloud(online_review, 'Main academy challenge', title="Main Academy Challenge Word Cloud")

generate_wordcloud(online_review, 'Education resources', title="Education resources Word Cloud")

generate_wordcloud(online_review, 'Recommendation', title="Recommendation Word Cloud")

generate_wordcloud(online_review, 'Non-primary academy challenge', title="Non-primary academy challenge Word Cloud")

"""## Bivariate Exploration"""

# CHecking for the number of unique value in each variable
online_review.iloc[:,0:-1].nunique()

fig, ax = plt.subplots(nrows=3, figsize = [12,8])

sns.countplot(data=online_review, x='Exam readiness', hue='Exam confidence',  ax=ax[0])
sns.countplot(data=online_review, x='Exam preparation', hue='Exam confidence', ax=ax[1])
sns.countplot(data=online_review, x='Family support', hue='Exam confidence', ax=ax[2])

plt.tight_layout();

"""### Interactive Contigency Table"""

import ipywidgets as widgets
from IPython.display import display

# Dropdown options
dropdown_var1 = widgets.Dropdown(
    options=['Gender', 'School', 'Location', 'Family support', 'Health issues', 'Age', 'CBT technical issues'],
    value='Gender',
    description='Row Variable:',
)

dropdown_var2 = widgets.Dropdown(
    options=['Exam confidence', 'Exam readiness', 'Exam preparation'],
    value='Exam confidence',
    description='Column Variable:',
)

# Function to update crosstab with color intensity based on values' size
def update_crosstab(var1, var2):
    # Compute crosstab between the selected variables
    multivariate_table = pd.crosstab(online_review[var1], online_review[var2])

    # Apply a background gradient to the crosstab to reflect the size of the values
    styled_table = multivariate_table.style.background_gradient(cmap='Greens')

    # Display the styled crosstab
    display(styled_table)

# Observe changes in dropdowns and update the colorful crosstab
widgets.interact(update_crosstab, var1=dropdown_var1, var2=dropdown_var2)

"""### Model Building"""

from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

# Import necessary libraries
from kmodes.kmodes import KModes

# Select the categorical columns
categorical_cols = ['Gender', 'Age', 'School', 'Exam', 'Location', 'Education',
       'Guardians Education', 'Main academy challenge',
       'Non-primary academy challenge', 'Exam readiness',
       'Education resources', 'CBT technical issues', 'Exam preparation',
       'Exam malpractice', 'After school study', 'Exam guidance',
       'Exam confidence', 'Health issues', 'Family support']

# Convert categorical columns to category type if not already
online_review[categorical_cols] = online_review[categorical_cols].astype('category')

# Convert categorical columns to numeric codes for K-Modes
for col in categorical_cols:
    online_review[col] = online_review[col].cat.codes

# Apply K-Modes clustering
kmodes = KModes(n_clusters=3, init='Cao', n_init=5, verbose=1, random_state=42)
cluster_labels = kmodes.fit_predict(online_review[categorical_cols])

# Add the cluster labels back to the original dataframe
online_review['Cluster'] = cluster_labels

# Function to visualize clusters
def visualize_clusters(x_feature, y_feature):
    plt.figure(figsize=(10, 7))
    sns.scatterplot(x=online_review[x_feature], y=online_review[y_feature],
                    hue=online_review['Cluster'], palette='viridis', s=100)
    plt.title(f'K-Modes Clustering: {x_feature} vs {y_feature}')
    plt.xlabel(x_feature)
    plt.ylabel(y_feature)
    plt.show()

    # Print out cluster centroids
    print("Cluster Centroids:\n", kmodes.cluster_centroids_)

# Create dropdowns for specified categorical features
x_dropdown = widgets.Dropdown(
    options=categorical_cols,
    description='Y-axis:',
)

# Y-axis dropdown with specific options
_dropdown = widgets.Dropdown(
    options=['Exam readiness', 'Exam preparation', 'Exam confidence'],
    description='X-axis:',
)

# Create an interactive plot
interactive_plot = widgets.interactive(visualize_clusters,
                                       x_feature=x_dropdown,
                                       y_feature=y_dropdown)
display(interactive_plot)
